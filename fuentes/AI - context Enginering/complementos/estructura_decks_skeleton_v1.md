# Estructura y Skeleton de Decks â€” Context Engineering
## Ãndice de Contenidos, Slides Base y GuÃ­a de Relleno

**VersiÃ³n:** 1.0  
**Formato:** Esqueleto de decks para armar en PowerPoint/Google Slides  
**Uso:** Usa como plantilla, reemplaza [CONTENIDO_A_INSERTAR] con datos/casos reales

---

# ğŸ“‘ Ãndice General de Decks

| Deck | Semanas | Audiencia | Slides | Formato | Objetivo |
|---|---|---|---|---|---|
| **Deck 1: El MÃ©todo** | 13-16 | Mixta (tech + managers) | 12-15 | Executive + tÃ©cnico | Explicar 3 Leyes + por quÃ© funciona |
| **Deck 2: Las 4 Fases** | 13-16 | ComitÃ©s tÃ©cnicos | 12-18 | TÃ©cnico detallado | ImplementaciÃ³n step-by-step |
| **Deck 3: Casos & ROI** | 13-16 | Executives + managers | 10-12 | Business focused | Pruebas + impacto $ |
| **Deck 4: Office Hours & Playbooks** | 5-12 | Equipos | 8-12 | PrÃ¡ctico | CÃ³mo funciona sesiÃ³n + ejemplos |
| **Deck 5: Governance & Seguridad** | 13-16 | IT/Security | 8-10 | TÃ©cnico/compliance | PolÃ­ticas + riesgos mitigados |
| **Deck 6: Pilotos y PrÃ³ximos Pasos** | Post-S20 | Managers + equipos | 6-8 | Operativo | CÃ³mo proponer + timeline piloto |

---

---

# ğŸ¯ DECK 1: El MÃ©todo (Context Engineering Framework)
## Slides: 12-15 | DuraciÃ³n: 20-25 minutos | Audiencia: Mixta

### **Estructura**

```
SLIDE 1:  Portada
SLIDE 2:  Agenda
SLIDE 3:  El Problema: Â¿Por quÃ© IA sola no es suficiente?
SLIDE 4:  La SoluciÃ³n: Las 3 Leyes
SLIDE 5:  LEY 1 Detalle - Estructurar Problema
SLIDE 6:  LEY 1 Ejemplo Vivo
SLIDE 7:  LEY 2 Detalle - Aportar Contexto
SLIDE 8:  LEY 2 Ejemplo Vivo
SLIDE 9:  LEY 3 Detalle - Verificar
SLIDE 10: LEY 3 Ejemplo Vivo
SLIDE 11: Impacto Real (Casos internos)
SLIDE 12: Â¿CuÃ¡ndo usar? Â¿CuÃ¡ndo no?
SLIDE 13: PrÃ³ximos Pasos (Office Hours)
[SLIDE 14-15: Optional - Deep Dives adicionales]
```

### **Contenido por Slide**

**SLIDE 1: Portada**
```
TÃ­tulo:     "Context Engineering Framework"
SubtÃ­tulo:  "Multiplicar impacto con IA: MÃ©todo universal"
Tu nombre:  "LÃ­der de AdopciÃ³n de IA â€” IngenierÃ­a de Contexto"
Fecha:      [Hoy]
Logo:       Ionos / Arsys
```

**SLIDE 2: Agenda**
```
â€¢ Â¿CuÃ¡l es el problema con IA hoy?
â€¢ Presentar las 3 Leyes (10 min)
â€¢ Casos reales en vivo (5 min)
â€¢ Â¿CuÃ¡ndo funciona? Â¿CuÃ¡ndo no? (3 min)
â€¢ CÃ³mo participar (Office Hours) (2 min)
```

**SLIDE 3: El Problema**
```
Izquierda:  âŒ Problema Actual
  "Uso ChatGPT â†’ Respuestas genÃ©ricas â†’ No sirve para mi contexto"
  "Gasto tiempo iterando â†’ La IA no entiende mi dominio"
  "Sin mÃ©todo â†’ Cada vez empiezo from scratch"

Derecha:    âœ… SoluciÃ³n Propuesta
  "MÃ©todo estructurado para contextualizar el problema"
  "Reutilizable en tareas similares"
  "Observable: mÃ©tricas antes/despuÃ©s"

Stat box:
  "En Ionos: 8 horas debugging â†’ 15 minutos (32x)"
```

**SLIDE 4: Las 3 Leyes**
```
Formato: 3 columnas o bloques verticales

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LEY 1       â”‚ LEY 2       â”‚ LEY 3       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ESTRUCTURAR â”‚ APORTAR     â”‚ VERIFICAR   â”‚
â”‚ PROBLEMA    â”‚ CONTEXTO    â”‚ RIGUROSAMENTEâ”‚
â”‚             â”‚             â”‚             â”‚
â”‚ âœ“ Objetivo  â”‚ âœ“ Dominio   â”‚ âœ“ Tests     â”‚
â”‚ âœ“ Restricc. â”‚ âœ“ Few-shot  â”‚ âœ“ Validar   â”‚
â”‚ âœ“ Criterios â”‚ âœ“ Verdad    â”‚ âœ“ Humano    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**SLIDE 5: LEY 1 Detalle**
```
TÃ­tulo: "Ley 1: Estructurar el Problema"

3 elementos OBLIGATORIOS:

ğŸ“Œ OBJETIVO CLARO
   "Â¿Exactamente quÃ© quiero lograr?"
   âŒ "Dame ideas" â†’ âœ… "Necesito analizar logs para encontrar causa latencia"

ğŸ“Œ RESTRICCIONES EXPLÃCITAS
   "Â¿QuÃ© NO puedo hacer?"
   âŒ "Hazlo rÃ¡pido" â†’ âœ… "Sin cambiar infraestructura, solo anÃ¡lisis"

ğŸ“Œ CRITERIOS DE Ã‰XITO
   "Â¿CÃ³mo sÃ© que funcionÃ³?"
   âŒ "Que sea bueno" â†’ âœ… "3 causas prioritizadas con ETA y esfuerzo"

ğŸ’¡ HeurÃ­stica: Si no puedes responder 3/3, tu problema no estÃ¡ claro.
```

**SLIDE 6: LEY 1 Ejemplo Vivo**
```
TÃ­tulo: "Ley 1 Ejemplo: AnÃ¡lisis de Logs"

ANTES (Vago):
  "Dame anÃ¡lisis de estos logs"
  âŒ Resultado: Resumen genÃ©rico, no Ãºtil

DESPUÃ‰S (Estructurado):
  "Contexto: Sistema Payments v2.4.1
   Objetivo: Encontrar causa latencia endpoint /transfer Ãºltimas 2h
   RestricciÃ³n: Sin cambiar config, solo anÃ¡lisis
   Formato: Tabla [Timestamp] [Componente] [MÃ©trica] [Causa] [AcciÃ³n]
   Criterios: 3 causas prioritizadas, impacto estimado + esfuerzo
   AquÃ­ estÃ¡n los logs: [LOGS SANITIZADOS]"
   
  âœ… Resultado: AnÃ¡lisis especÃ­fico, listo para usar
```

**SLIDE 7: LEY 2 Detalle**
```
TÃ­tulo: "Ley 2: Aportar Contexto Rico"

La IA no adivina. Necesita informaciÃ³n concreta:

ğŸ“š CONTEXTO DOMINIO
   "Â¿En quÃ© sistema estoy? Â¿VersiÃ³n?"
   Ejemplo: "Sistema Payments, v2.4.1, language Python"

ğŸ¯ CASOS PREVIOS (Few-Shot)
   "Â¿Hay ejemplos similares?"
   Ejemplo: 2-3 casos histÃ³ricos del mismo patrÃ³n

ğŸ“Š VERDAD DEL TERRENO
   "Â¿CuÃ¡les son las restricciones reales?"
   Ejemplo: "SLA mÃ¡ximo 5min, usuarios US-East only"

ğŸ’¡ El contexto es lo que diferencia genÃ©rico de especÃ­fico.
```

**SLIDE 8: LEY 2 Ejemplo Vivo**
```
TÃ­tulo: "Ley 2 Ejemplo: Code Review"

ANTES (Sin contexto):
  "Revisa este cÃ³digo"
  [Solo el cÃ³digo]
  âŒ Resultado: RevisiÃ³n genÃ©rica

DESPUÃ‰S (Con contexto):
  "Contexto: Repo Python Django, testing pytest
   Few-shot: [Link 2 reviews previos similaresaprobados]
   RestricciÃ³n: No mockear datetime sin necesidad
   Problema especÃ­fico: FunciÃ³n X accede BD 3 veces, optimizar
   AquÃ­ estÃ¡ el cÃ³digo: [CODE]"
   
  âœ… Resultado: Review profundo, reutilizable como template
```

**SLIDE 9: LEY 3 Detalle**
```
TÃ­tulo: "Ley 3: Verificar Rigurosamente"

No confÃ­es en IA al 100%. Valida segÃºn criticidad:

ğŸ”´ CRÃTICO (ProducciÃ³n, dinero, PII)
   VerificaciÃ³n: Tests + Peer review + Canary + Rollback plan
   Tiempo: 30+ minutos

ğŸŸ¡ MEDIANO (Cambios operativos)
   VerificaciÃ³n: Tests + Peer review
   Tiempo: 15 minutos

ğŸŸ¢ BAJO (AnÃ¡lisis, brainstorm)
   VerificaciÃ³n: Lectura rÃ¡pida + Sentido comÃºn
   Tiempo: 2 minutos

ğŸ’¡ Regla: Mayor criticidad â†’ Mayor verificaciÃ³n
```

**SLIDE 10: LEY 3 Ejemplo Vivo**
```
TÃ­tulo: "Ley 3 Ejemplo: Cuando FallÃ³ y CÃ³mo Lo Arreglamos"

CASO REAL:
  Paso 1: IA genera SQL para query en prod
  Paso 2: No verificamos, lo pusimos directo
  Paso 3: Query N+1 â†’ Timeout â†’ Incident
  âŒ LecciÃ³n: Criticidad ALTA, validaciÃ³n insuficiente

SOLUCIÃ“N:
  Paso 1: IA genera SQL
  Paso 2: Ejecutamos en DEV, medimos performance
  Paso 3: Peer review (otro SRE valida patrÃ³n)
  Paso 4: Canary en staging 10% trÃ¡fico
  Paso 5: Monitor + Rollback plan listo
  Paso 6: Prod gradual (100% en 30 min con observabilidad)
  âœ… LecciÃ³n: La verificaciÃ³n es inseparable del mÃ©todo
```

**SLIDE 11: Impacto Real**
```
TÃ­tulo: "Casos Reales en Ionos"

[Insertar 2-3 mejores casos documentados de tracker]

Caso 1:
  â€¢ Backend Dev: Code review 1h â†’ 8 min (87% ROI)
  â€¢ MÃ©trica: PR Review Time
  â€¢ Replicable: SÃ

Caso 2:
  â€¢ SRE: Diagnosis incident 3h â†’ 15 min (92% ROI)
  â€¢ MÃ©trica: MTTR Incident
  â€¢ Replicable: PARCIAL (necesita contexto)

Caso 3:
  â€¢ Soporte: Respuesta tickets 40 min â†’ 5 min (88% ROI)
  â€¢ MÃ©trica: Ticket Response Time
  â€¢ Replicable: SÃ

ACUMULADO S1-S5:
  â†’ 7 personas habilitadas
  â†’ 30+ horas ahorradas
  â†’ 89% ROI promedio
```

**SLIDE 12: Â¿CuÃ¡ndo Usar? Â¿CuÃ¡ndo No?**
```
TÃ­tulo: "Matriz: CuÃ¡ndo Context Engineering Brilla"

IDEAL PARA:
  âœ… Hay documentaciÃ³n (runbooks, cÃ³digo, configs)
  âœ… Hay precedentes (casos previos similares)
  âœ… MÃ©trica clara (testeable, observable)
  âœ… Problema repetible (no one-off)
  
NO IDEAL PARA:
  âŒ DecisiÃ³n humana irreemplazable (despidos, evaluaciones)
  âŒ InformaciÃ³n real-time exterior (precios hoy, noticias)
  âŒ Problema completamente nuevo (sin referencia)
  âŒ Creatividad pura (sin patrÃ³n)

PREGUNTA SIMPLE:
  "Â¿Hay algÃºn humano experto que sabe resolver esto?"
  SÃ â†’ Context Engineering puede ayudar
  NO â†’ Probablemente no
```

**SLIDE 13: PrÃ³ximos Pasos**
```
TÃ­tulo: "Â¿Interesado? CÃ³mo Participar"

3 opciones:

1ï¸âƒ£ SHOW & TELL (Semana prÃ³xima)
   â€¢ 60 minutos
   â€¢ Demos en vivo
   â€¢ Sin PowerPoint, casos reales
   
2ï¸âƒ£ OFFICE HOURS (Cada [DÃA] [HORA])
   â€¢ 45 minutos
   â€¢ Trae TU problema
   â€¢ Trabajamos juntos
   
3ï¸âƒ£ PILOTO (Semanas 21-32)
   â€¢ 12 semanas
   â€¢ Tu equipo + facilitador
   â€¢ MÃ©tricas antes/despuÃ©s

Contacto:
  Email: [TU EMAIL]
  Slack: #context-engineering
  Calendar: [LINK PÃšBLICO A OFFICE HOURS]
```

**SLIDE 14 [OPCIONAL]: FAQs**
```
P: Â¿Esto reemplaza el juicio humano?
R: No, lo complementa. La verificaciÃ³n es obligatoria.

P: Â¿Funciona con cualquier herramienta?
R: El mÃ©todo es agnÃ³stico. Hoy usamos ChatGPT/Claude, maÃ±ana otras.

P: Â¿CuÃ¡nto tiempo de aprendizaje?
R: 4-6 semanas si prÃ¡cticas 2-3 casos/semana.

P: Â¿Funciona para mi rol/equipo?
R: Lo hemos aplicado en Dev, SRE, Soporte, RRHH, Marketing. SÃ funciona.
```

**SLIDE 15 [OPCIONAL]: Referencias**
```
Documentos clave:
  â€¢ Context Engineering Framework (1-pager)
  â€¢ Context Engineering EXTENDED (profundidad tÃ©cnica)
  â€¢ FAQ & Objeciones
  â€¢ Playbook Quick Start

Links:
  [Links a documentaciÃ³n interna / Space de Ionos]
```

---

---

# ğŸ—ï¸ DECK 2: Las 4 Fases â€” ImplementaciÃ³n
## Slides: 12-18 | DuraciÃ³n: 30-40 minutos | Audiencia: ComitÃ©s tÃ©cnicos

### **Estructura**

```
SLIDE 1:  Portada
SLIDE 2:  Agenda + Timeline 32 semanas
SLIDE 3:  VisiÃ³n General: 4 Fases Funnel
SLIDE 4:  FASE 1 Foundation - DefiniciÃ³n
SLIDE 5:  FASE 1 Foundation - Actividades & MÃ©tricas
SLIDE 6:  FASE 1 Foundation - DoD (Definition of Done)
SLIDE 7:  FASE 2 Integration - DefiniciÃ³n
SLIDE 8:  FASE 2 Integration - Actividades & MÃ©tricas
SLIDE 9:  FASE 2 Integration - DoD
SLIDE 10: FASE 3 Measurement - DefiniciÃ³n
SLIDE 11: FASE 3 Measurement - Actividades & MÃ©tricas
SLIDE 12: FASE 3 Measurement - DoD
SLIDE 13: FASE 4 Governance - DefiniciÃ³n
SLIDE 14: FASE 4 Governance - Actividades & MÃ©tricas
SLIDE 15: FASE 4 Governance - DoD + Anti-patrones
SLIDE 16: Roadmap Completo (12 semanas piloto)
SLIDE 17: Riesgos y Mitigaciones
SLIDE 18: Q&A / Siguientes pasos
```

### **Contenido Clave por Slide**

**SLIDE 1: Portada**
```
TÃ­tulo: "Context Engineering: Las 4 Fases de ImplementaciÃ³n"
SubtÃ­tulo: "De Foundation a Governance â€” 12 semanas por equipo"
Fecha & Facilitador: [TUS DATOS]
```

**SLIDE 3: VisiÃ³n General 4 Fases**
```
Formato: GrÃ¡fico de embudo/flujo

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FOUNDATION   â”‚ Semana 1-3: Bases, capacitaciÃ³n, casos pequeÃ±os
â”‚ (6-8 SRs)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INTEGRATION  â”‚ Semana 4-6: IntegraciÃ³n en workflow, escalada
â”‚ (3-5 SRs)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MEASUREMENT  â”‚ Semana 7-9: MÃ©tricas, anÃ¡lisis ROI
â”‚ (2-3 SRs)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GOVERNANCE   â”‚ Semana 10-12: Sostenibilidad, polÃ­ticas, scaling
â”‚ (1-2 SRs)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

MÃ©trica paralela: AutonomÃ­a sube, facilitation baja
  Semana 1: 90% facilitation, 10% autÃ³nomo
  Semana 12: 10% facilitation, 90% autÃ³nomo
```

**SLIDE 4-6: FASE 1 Foundation**

**SLIDE 4:**
```
TÃ­tulo: "FASE 1: Foundation (Semanas 1-3)"

Objetivo: Capacitar equipo en 3 Leyes, validar en casos pequeÃ±os

Entrada (Pre-requisito):
  âœ“ Equipo confirmado (4-8 personas)
  âœ“ Problem statement claro (quÃ© vamos a automatizar)
  âœ“ Acceso a documentaciÃ³n/datos necesarios

Hito intermedio (Semana 2):
  âœ“ 3-4 sesiones de capacitaciÃ³n completadas
  âœ“ Primeros 2-3 casos pequeÃ±os ejecutados
  âœ“ Feedback inicial incorporado
```

**SLIDE 5:**
```
TÃ­tulo: "FASE 1: Actividades & MÃ©tricas"

Actividades principales:
  1. Kickoff formal (1h)
  2. Show & Tell del mÃ©todo (1h)
  3. Office Hours x3 (45 min cada uno)
  4. DocumentaciÃ³n inicial de 2-3 casos
  5. Primer feedback de participantes

MÃ©tricas esperadas (S3):
  â˜ % participaciÃ³n en sesiones (target: 80%+)
  â˜ # casos pequeÃ±os completados (target: 3-5)
  â˜ # personas diciendo "ahora lo entiendo" (target: 100%)
  â˜ NPS inicial (Net Promoter Score, target: >7/10)
  â˜ Anti-patrones detectados (target: 0-2)
```

**SLIDE 6:**
```
TÃ­tulo: "FASE 1: Definition of Done"

El equipo pasa a PHASE 2 SOLO si:

âœ… MANDATORY:
   â€¢ 100% del equipo asistiÃ³ â‰¥2 sesiones
   â€¢ 3+ casos documentados (incluso si pequeÃ±os)
   â€¢ 0 incidents causados por Method mis-use
   â€¢ Feedback consolidado (1-pager)

âš ï¸ NICE-TO-HAVE:
   â€¢ â‰¥60% de casos son replicables
   â€¢ 1 champion identificado
   â€¢ Template de prompt creado para dominio

âŒ BLOCKER (Si pasa, repetir F1):
   â€¢ <50% participaciÃ³n en sesiones
   â€¢ Casos tienen datos sensibles expuestos
   â€¢ Equipo dice "esto no nos sirve"
```

**SLIDE 7-9: FASE 2 Integration** [Mismo formato que F1, adapt contenido]

```
SLIDE 7 - DefiniciÃ³n:
  Objetivo: Integrar mÃ©todo en workflow diario, escalar automÃ¡ticamente
  Entrada: Completada FASE 1
  Hito S6: Workflow integrado en 60%+ del equipo

SLIDE 8 - Actividades:
  1. IntegraciÃ³n en CI/CD o sistemas existentes
  2. Office Hours 2x/semana (focus en escalada)
  3. Training de 1-2 champions
  4. 5-7 casos nuevos documentados
  5. Troubleshooting + iteraciÃ³n

  MÃ©tricas:
  â€¢ # casos completados sin facilitador (target: 3-5)
  â€¢ % equipo usando mÃ©todo de forma autÃ³noma (target: 40-60%)
  â€¢ % casos "Replicable: SÃ" (target: 50%+)
  â€¢ ROI promedio acumulado (target: >70%)

SLIDE 9 - DoD:
  âœ… MANDATORY:
     â€¢ â‰¥1 piloto sin facilitador completado con Ã©xito
     â€¢ 5+ casos documentados total
     â€¢ 1-2 champions pueden facilitar solos

  âŒ BLOCKER:
     â€¢ <30% del equipo usa mÃ©todo
     â€¢ Casos tienen issues de data leakage
```

**SLIDE 10-12: FASE 3 Measurement** [Adaptado]

```
SLIDE 10 - DefiniciÃ³n:
  Objetivo: Medir impacto real, cuantificar ROI organizacional
  Entrada: Completada FASE 2
  Hito S9: MÃ©tricas validadas, ROI claro

SLIDE 11 - Actividades:
  1. RecopilaciÃ³n datos 6-9 meses atrÃ¡s (before/after)
  2. AnÃ¡lisis de anomalÃ­as (Â¿quÃ© casos funcionaron/no?)
  3. Entrevistas 1:1 para validar mÃ©tricas
  4. Reporte consolidado + visualizaciones

  MÃ©tricas por medir:
  â€¢ Tiempo ahorrado total (horas/mes)
  â€¢ Impacto por persona (MTTA, MTTR, etc.)
  â€¢ Calidad mejorada (defectos â†“, throughput â†‘)
  â€¢ AutonomÃ­a ganada (nuevos dominios donde operativo)

SLIDE 12 - DoD:
  âœ… MANDATORY:
     â€¢ Reporte de ROI firmado (manager + facilitador)
     â€¢ 3+ visualizaciones de impacto
     â€¢ Feedback de all participantes incorporado

  âŒ BLOCKER:
     â€¢ MÃ©tricas no son validables / inconsistentes
```

**SLIDE 13-15: FASE 4 Governance** [Adaptado]

```
SLIDE 13 - DefiniciÃ³n:
  Objetivo: Sostenibilidad, polÃ­ticas formales, preparar escalada
  Entrada: Completada FASE 3
  Hito S12: Governance en lugar, escalada habilitada

SLIDE 14 - Actividades:
  1. Definir ownership del mÃ©todo post-piloto
  2. PolÃ­ticas de datos formales (PolÃ­tica de Datos v1.0)
  3. SLA del facilitador (si continÃºa apoyando)
  4. Plan de escalada a otros equipos
  5. DocumentaciÃ³n final (runbooks, templates, FAQs)

  MÃ©tricas:
  â€¢ PolÃ­tica de datos aprobada por IT/Security (target: S11)
  â€¢ % equipo puede facilitar a otros (target: 50%+)
  â€¢ Tiempo de facilitador post-fase (est: 20% vs 60% inicial)

SLIDE 15 - DoD + Anti-patrones:
  âœ… MANDATORY:
     â€¢ PolÃ­tica de Datos v1.0 aprobada
     â€¢ Ownership definido (quiÃ©n mantiene)
     â€¢ Plan de escalada para prÃ³ximo equipo

  âŒ ANTI-PATTERNS (Evitar):
     â€¢ "Governance = prohibiciÃ³n de IA" â†’ NO, governance = seguridad
     â€¢ "Facilitator desaparece dÃ­a 1 de F4" â†’ NO, debe supervisar
     â€¢ "MÃ©tricas se detienen en S12" â†’ NO, continuar tracking
```

**SLIDE 16: Roadmap Completo 12 semanas**
```
Formato: Timeline visual

Semana 1-3:     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ FOUNDATION
Semana 4-6:            â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ INTEGRATION
Semana 7-9:                   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ MEASUREMENT
Semana 10-12:                        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ GOVERNANCE

Hitos clave:
  S1:  Kickoff
  S3:  F1 DoD alcanzado, equipo entiende mÃ©todo
  S6:  F2 DoD alcanzado, escalada autÃ³noma comienza
  S9:  F3 DoD alcanzado, ROI validado
  S12: F4 DoD alcanzado, listo para siguiente equipo

Paralelo:
  Oficina Hours: Cada [DÃA] [HORA] (consistente)
  DocumentaciÃ³n: Viva, actualizar cada 2 semanas
  MÃ©tricas: Tracker semanal, reporte cada 4 semanas
```

**SLIDE 17: Riesgos y Mitigaciones**
```
Formato: Tabla

RIESGO | PROBABILIDAD | IMPACTO | MITIGACIÃ“N
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"Equipo no participa activamente" | Alta | Alto | Conectar con problemas reales del equipo, NO mandato
"Casos tienen data leakage" | Media | Alto | PolÃ­tica de datos + checklist pre-uso
"ROI no es medible/validable" | Media | Medio | Definir mÃ©tricas S0, trackear desde dÃ­a 1
"Method fatigue (demasiado framework)" | Baja | Bajo | Simplificar, focus en 3 Leyes, no 100 reglas
"Siguiente equipo no quiere participar" | Baja | Medio | Use casos Ã©xito para evangelizar
```

**SLIDE 18: Q&A / Siguientes Pasos**
```
Preguntas esperadas:
  Q: Â¿Esto es mandatorio?
  R: No, es opt-in. Pero los resultados son convincentes.

  Q: Â¿QuiÃ©n facilita?
  R: [TU NOMBRE] en F1-F3, champions en F4+

  Q: Â¿CuÃ¡l es el commitment de tiempo del equipo?
  R: 4-6h/semana en F1, baja en F4 (eventual)

  Q: Â¿Garantizan ROI?
  R: El mÃ©todo funciona. Pero ROI depende de caso de uso. Rango tÃ­pico: 70-95%.

PrÃ³ximos pasos:
  1. Equipos interesados, levantar mano
  2. Kickoff formal (S1 o S21, segÃºn timeline)
  3. Primera sesiÃ³n Show & Tell la prÃ³xima semana
```

---

---

# ğŸ’° DECK 3: Casos & ROI
## Slides: 10-12 | DuraciÃ³n: 15-20 minutos | Audiencia: Executives + Managers

### **Estructura**

```
SLIDE 1:  Portada
SLIDE 2:  Executive Summary (1 slide con nÃºmeros)
SLIDE 3-8: [INSERTAR 5-6 CASOS REALES]
SLIDE 9:  ROI Consolidado Organizacional
SLIDE 10: AnÃ¡lisis por Rol/Equipo
SLIDE 11: Benchmarking (vs mercado, si aplica)
SLIDE 12: ConclusiÃ³n & Business Case Preview
```

### **Contenido Clave**

**SLIDE 1: Portada**
```
TÃ­tulo: "Context Engineering: Casos & ROI Organizacional"
SubtÃ­tulo: "Resultados reales de [S1-SX], X semanas de implementaciÃ³n"
PerÃ­odo: "Octubre - [FECHA ACTUAL]"
```

**SLIDE 2: Executive Summary (Key Numbers)**
```
[Grande, nÃºmeros destacados]

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  7 PERSONAS â”‚ 30+ HORAS   â”‚   89%       â”‚  4 EQUIPOS  â”‚
â”‚ HABILITADAS â”‚  AHORRADAS  â”‚   ROI       â”‚  IMPACTADOS â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

        ğŸ’° ~â‚¬4,500 en valor organizacional (estimado)
        
Key takeaway: "El mÃ©todo demuestra valor, es replicable, 
estÃ¡ listo para escalada"
```

**SLIDE 3-8: Casos Individuales**

[Insertar 1 caso por slide, formato estÃ¡ndar]

**Formato estÃ¡ndar por caso:**

```
TÃTULO: [Nombre descriptivo del caso]

PERSONA/EQUIPO: [Dev-A / SRE-B / Soporte-C] | Rol: [Backend Dev]

PROBLEMA (antes):
  "Tardaba 2h 30min en analizar logs de incident porque..."
  
CONTEXTO USADO:
  âœ“ Logs sanitizados (>1000 lÃ­neas)
  âœ“ 2 postmortems histÃ³ricos similares
  âœ“ Runbook de troubleshooting

SOLUCIÃ“N (Prompt):
  [Resumir 1-2 lÃ­neas clave del prompt]

RESULTADO (despuÃ©s):
  âœ“ 15 minutos para anÃ¡lisis completo
  âœ“ 3 causas prioritizadas + ETA + esfuerzo
  âœ“ AnÃ¡lisis pasÃ³ peer review sin cambios

MÃ‰TRICAS:
  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 92% ROI
  Tiempo: 2h 30min â†’ 15 min
  Herramienta: Claude Pro
  Replicable: âœ… SÃ (otros SREs la pueden usar)
  
QUOTE:
  "Esto normalmente tomarÃ­a toda mi maÃ±ana. 
   En 15 minutos tenÃ­a anÃ¡lisis validado. Game-changer."
   â€” [PERSONA]

IMPACTO ORGANIZACIONAL:
  â€¢ Si escalamos a 8 SREs â†’ 18-20h ahorradas/semana
  â€¢ Incident response time â†“ 85%
  â€¢ Escalabilidad sin contratar mÃ¡s SREs
```

[Repetir SLIDE 3-8 con 6 mejores casos del tracker]

**SLIDE 9: ROI Consolidado Organizacional**
```
TÃ­tulo: "ROI Total: Octubre - [HOY]"

VisualizaciÃ³n: GrÃ¡fico de barras o timeline

ANTES vs DESPUÃ‰S:

MÃ‰TRICAS OPERATIVAS:
  â€¢ MTTA (Mean Time To Ack): 45 min â†’ 20 min (-56%)
  â€¢ MTTR (Mean Time To Resolve): 3h â†’ 1h (-67%)
  â€¢ Ticket Response Time: 40 min â†’ 5 min (-88%)
  â€¢ Code Review Cycle: 1h â†’ 8 min (-87%)
  â€¢ Doc Generation: 3h â†’ 25 min (-86%)
  
IMPACTO HUMANO:
  â€¢ Personas habilitadas: 7 (target S12: 15-25)
  â€¢ Equipos activos: 4 (target S12: 4-6)
  â€¢ Champions identificados: 2 (target S12: 3-5)
  
MÃ‰TRICAS FINANCIERAS (Estimado):
  â€¢ Tiempo ahorrado: 30+ horas (primeras 5 semanas)
  â€¢ Costo/hora (seÃ±or): â‚¬150
  â€¢ Valor generado: ~â‚¬4,500
  â€¢ Proyectado S12: ~â‚¬35-50k (con escalada)
  
CALIDAD:
  â€¢ Defectos pre-prod: [% mejorado si aplica]
  â€¢ Throughput: [% mejorado si aplica]
```

**SLIDE 10: AnÃ¡lisis por Rol/Equipo**
```
TÃ­tulo: "Impacto por Rol: DistribuciÃ³n Horizontal"

Tabla/VisualizaciÃ³n:

ROL        | CASOS | ROI AVG | MEJOR CASO | PEOR CASO
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Dev        | 2     | 82%    | 87%        | 78%
SRE        | 2     | 92%    | 92%        | 92%
Soporte    | 1     | 88%    | 88%        | -
RRHH       | 1     | 92%    | 92%        | -
Operaciones| 1     | 92%    | 92%        | -
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL      | 7     | 89%    | 92%        | 78%

Key insight:
  "No es concentrado en 1 equipo. El mÃ©todo funciona 
   horizontalmente (Dev, SRE, Soporte, RRHH, Ops).
   Esto demuestra universalidad."
```

**SLIDE 11: Benchmarking (Contexto de Mercado)**
```
TÃ­tulo: "Â¿CÃ³mo nos comparamos?"

Info: Si tienes benchmarks internos o externos

IONOS vs MERCADO:
  â€¢ Industria Tech tÃ­pica: 40-60% ROI en initiatives de productividad
  â€¢ Ionos Context Engineering: 89% ROI en 5 semanas
  â€¢ ConclusiÃ³n: 48% mejor que baseline

TIME-TO-VALUE:
  â€¢ TÃ­pico (herramientas): 12-16 semanas
  â€¢ Ionos (mÃ©todo): 2-3 semanas hasta primer caso
  â€¢ ConclusiÃ³n: 5-8x mÃ¡s rÃ¡pido

ESCALABILIDAD:
  â€¢ Per-person ROI no disminuye con mÃ¡s gente
  â€¢ El mÃ©todo es transferible, no hay degradaciÃ³n
  â€¢ ConclusiÃ³n: ROI escala linealmente
```

**SLIDE 12: ConclusiÃ³n & Business Case Preview**
```
TÃ­tulo: "ConclusiÃ³n: Listo para Escalada"

3 datos clave:

1. âœ… VALIDADO: 7 personas, 4 equipos, 89% ROI promedio
   "El mÃ©todo funciona en la realidad Ionos"

2. âœ… UNIVERSAL: Dev, SRE, Soporte, RRHH, Ops
   "No es niche, aplica horizontalmente"

3. âœ… REPLICABLE: 85% de casos son replicables
   "Otros pueden hacerlo solos (no necesitan facilitador)"

PRÃ“XIMOS PASOS (Semanas 13-20):
  â†’ 2-3 pilotos formales de 12 semanas
  â†’ DocumentaciÃ³n de anti-patrones aprendidos
  â†’ Business case L6 (impacto multiplicador)

INVERSIÃ“N REQUERIDA:
  â€¢ Licencias IA (ChatGPT/Claude): [Xâ‚¬/mes]
  â€¢ Tiempo facilitador: [Y h/semana]
  â€¢ Tiempo equipos: [Z h/semana]
  
ESPERADO POST-ESCALADA (AÃ±o 1):
  â€¢ 20-30 personas habilitadas
  â€¢ 6-8 equipos en implementaciÃ³n
  â€¢ â‚¬80-150k en valor organizacional estimado
```

---

---

# ğŸ› ï¸ DECK 4: Office Hours & Playbooks
## Slides: 8-12 | DuraciÃ³n: 15 minutos | Audiencia: Equipos

### **Estructura**

```
SLIDE 1:  Portada
SLIDE 2:  Â¿QuÃ© es una Office Hour?
SLIDE 3:  Estructura de 45 Minutos
SLIDE 4-6: Playbook Ejemplo 1 (Helpdesk / Dev / RRHH)
SLIDE 7-8: CÃ³mo Unirse + Calendario
```

**SLIDE 3: Estructura 45 min**
```
â±ï¸ 5 min:   INTRO
   "Â¿CuÃ¡l es tu problema hoy?"

â±ï¸ 10 min:  ESTRUCTURACIÃ“N (Ley 1)
   "Junto contigo, aclaramos quÃ© necesitas"

â±ï¸ 15 min:  CONTEXTO (Ley 2)
   "Reunimos informaciÃ³n relevante"

â±ï¸ 10 min:  APLICAR MÃ‰TODO (Prompts)
   "Escribimos prompt y ejecutamos"

â±ï¸ 5 min:   VALIDACIÃ“N + DOCUMENTACIÃ“N
   "Validamos resultado, documentamos caso"

OUTCOME: Sales con caso documentado + template reusable
```

---

---

# ğŸ”’ DECK 5: Governance & Seguridad
## Slides: 8-10 | DuraciÃ³n: 15 minutos | Audiencia: IT/Security

### **Estructura**

```
SLIDE 1:  Portada
SLIDE 2:  El DesafÃ­o (PII, datos sensibles, compliance)
SLIDE 3-5: Soluciones implementadas
SLIDE 6:  PolÃ­tica de Datos v1.0
SLIDE 7:  Monitoreo & AuditorÃ­a
SLIDE 8:  Riesgos Residuales
SLIDE 9-10: Escaladas
```

**Contenido clave:**

Usar contenido de documento "PolÃ­tica de Datos v1.0" que creamos.

---

---

# ğŸš€ DECK 6: Pilotos y PrÃ³ximos Pasos
## Slides: 6-8 | DuraciÃ³n: 10 minutos | Audiencia: Managers + Equipos

### **Estructura**

```
SLIDE 1:  Portada
SLIDE 2:  Propuesta de Piloto (Plantilla)
SLIDE 3:  Timeline 12 semanas (4 Fases)
SLIDE 4:  Commitment requerido
SLIDE 5:  MÃ©tricas de Ã©xito
SLIDE 6:  Riesgos & MitigaciÃ³n
SLIDE 7-8: CÃ³mo registrarse
```

**SLIDE 2: Plantilla de Propuesta**
```
PILOTO: [Nombre]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Equipo(s): [SRE / Dev Backend / Soporte]
DuraciÃ³n: 12 semanas (4 Fases Foundationâ†’Governance)
Commitment: [X h/semana del equipo]

PROBLEMA A RESOLVER:
  "En SRE, tardamos 3h en [problema], queremos 30 min"

MÃ‰TRICA Ã‰XITO:
  â€¢ ANTES: 3h por incident
  â€¢ DESPUÃ‰S: 30 min por incident (target)
  â€¢ ROI esperado: 90%+

FACILITATION:
  [TU NOMBRE], LÃ­der de AdopciÃ³n IA
  Sesiones: [DÃA/HORA regulares]

RIESGOS:
  â€¢ Si <50% participaciÃ³n â†’ Riesgo de no completar
  â€¢ MitigaciÃ³n: Conectar con pain point real del equipo
```

---

---

## ğŸ“Œ GUÃA DE RELLENO: CÃ³mo Usar Esta Estructura

### Antes de crear decks:

1. **ReÃºne datos de tracker**
   - Top 3-5 casos mejor documentados
   - MÃ©tricas consolidadas S1-SX

2. **Extrae quotes**
   - 1-2 citados de participantes
   - Permisos de uso (preguntar si publicar nombre o anonimizar)

3. **Valida nÃºmeros**
   - Â¿ROI % son correctos?
   - Â¿Herramientas usadas son actuales?
   - Â¿Fechas y semanas son consistentes?

### Durante creaciÃ³n de slides:

1. **MantÃ©n consistencia visual**
   - Mismo color/tipografÃ­a entre decks
   - Logos Ionos/Arsys en header
   - Numbering de slides consistente

2. **Adapta ejemplos genÃ©ricos a TUS casos reales**
   - [INSERTAR AQUÃ] â†’ Busca en tracker
   - [ESTADÃSTICA] â†’ Calcula desde datos reales

3. **Pide feedback**
   - A manager: "Â¿NÃºmeros son correctos?"
   - A participantes: "Â¿Puedo publicar tu caso?"
   - A IT/Security: "Â¿Deck de Governance estÃ¡ OK?"

### DespuÃ©s de crear decks:

1. **Prepara speaker notes**
   - Notas bajo cada slide con transiciones
   - Timing (cuÃ¡ntos minutos por slide)
   - Frases clave (no leer textualmente)

2. **Haz dry-run**
   - Presenta a manager / amigo
   - Mide tiempo
   - Ajusta si es muy larga/corta

3. **Prepara Q&A**
   - Anticipa preguntas por audiencia
   - Notas con respuestas

---

## ğŸ“Š Resumen de Decks + Timeline

| Deck | Semanas | Auditorio | PropÃ³sito | Prerequisite |
|---|---|---|---|---|
| **1: MÃ©todo** | 13-16 | Mixta | Explicar quÃ©/por quÃ© | Cases documentados |
| **2: 4 Fases** | 13-16 | ComitÃ©s tÃ©cnicos | CÃ³mo implementar | Phases content ready |
| **3: Casos & ROI** | 13-16 | Execs | Probar valor $ | Top 6 cases |
| **4: Office Hours** | 5-12 | Equipos | CÃ³mo participar | Playbooks ready |
| **5: Governance** | 13-16 | IT/Security | Riesgos mitigados | Policy v1.0 aprob |
| **6: Pilotos** | Post-20 | Managers | CÃ³mo proponer piloto | 4 Fases documentadas |

---

**VersiÃ³n 1.0 | Octubre 2025 | Estado: Template listo para rellenar con datos reales**

**PrÃ³ximo paso:** Elige 1 deck, reÃºne datos de tracker, comienza a rellenar en PowerPoint/Google Slides